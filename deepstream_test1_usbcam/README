*****************************************************************************
* Copyright (c) 2018-2021 NVIDIA Corporation.  All rights reserved.
*
* NVIDIA Corporation and its licensors retain all intellectual property
* and proprietary rights in and to this software, related documentation
* and any modifications thereto.  Any use, reproduction, disclosure or
* distribution of this software and related documentation without an express
* license agreement from NVIDIA Corporation is strictly prohibited.
*****************************************************************************

# Prequisites:

- Please follow instructions in the apps/sample_apps/deepstream-app/README on how
to install the prequisites for Deepstream SDK, the DeepStream SDK itself and the
apps.

- You must have the following development packages installed:
``` 
   GStreamer-1.0
   GStreamer-1.0 Base Plugins
   GStreamer-1.0 gstrtspserver
   X11 client-side library
```
- To install these packages, execute the following command: 
```
   sudo apt-get install libgstreamer-plugins-base1.0-dev libgstreamer1.0-dev \
   libgstrtspserver-1.0-dev libx11-dev
```
- To get support formats:
```
v4l2-ctl -d /dev/video1 --list-formats-ext
```
- We have verified v4l2src on the device. It shall work if you correctly configure the v4l2 source to meet supported mode in width, height, format, framerate. Suggest you break down the pipeline with fakesink. See if the source can be successfully converted to "video/x-raw(memory:NVMM),format=NV12". \
```
gst-launch-1.0 v4l2src device="/dev/video0" ! video/x-raw,format=YUY2,width=640,height=480,framerate=30/1 ! nvvideoconvert ! "video/x-raw(memory:NVMM),format=NV12" ! fakesink
```
# Compilation Steps:
```
  $ Set CUDA_VER in the MakeFile as per platform.
      For Jetson, CUDA_VER=10.2
      For x86, CUDA_VER=11.4
  $ sudo make
```
- To run:
```
  $ ./deepstream-test1-app <h264_elementary_stream>
```
# Attention
NOTE: To compile the sources, run make with "sudo" or root permission.

This document shall describe about the sample deepstream-test1 application.

It is meant for simple demonstration of how to use the various DeepStream SDK
elements in the pipeline and extract meaningful insights from a video stream.

This sample creates instance of "nvinfer" element. Instance of
the "nvinfer" uses TensorRT API to execute inferencing on a model. Using a
correct configuration for a nvinfer element instance is therefore very
important as considerable behaviors of the instance are parameterized
through these configs.

For reference, here are the config files used for this sample :
1. The 4-class detector (referred to as pgie in this sample) uses
    dstest1_pgie_config.txt

In this sample, we first create one instance of "nvinfer", referred as the pgie.
This is our 4 class detector and it detects for "Vehicle , RoadSign, TwoWheeler,
Person".
nvinfer element attach some MetaData to the buffer. By attaching
the probe function at the end of the pipeline, one can extract meaningful
information from this inference. Please refer the "osd_sink_pad_buffer_probe"
function in the sample code. For details on the Metadata format, refer to the
file "gstnvdsmeta.h"

